package db

import (
	"context"
	"fmt"

	"github.com/rs/zerolog/log"
	"github.com/scalarorg/data-models/chains"
	"github.com/scalarorg/data-models/scalarnet"
	"gorm.io/gorm"
)

// find relay datas by token sent attributes
func (db *DatabaseAdapter) FindPendingBtcTokenSent(sourceChain string, height int) (map[uint64][]*chains.TokenSent, error) {
	//1. Find all distinct block numbers with pending token sents up to the given height
	var distinctBlockNumbers []uint64
	result := db.RelayerClient.Model(&chains.TokenSent{}).
		Select("DISTINCT block_number").
		Where("source_chain = ? AND block_number <= ? AND status = ?",
			sourceChain,
			height,
			string(chains.TokenSentStatusPending)).
		Order("block_number ASC").
		Find(&distinctBlockNumbers)

	if result.Error != nil {
		return nil, fmt.Errorf("FindPendingBtcTokenSent with error: %w", result.Error)
	}

	if len(distinctBlockNumbers) == 0 {
		log.Warn().
			Str("sourceChain", sourceChain).
			Msgf("[DatabaseAdapter] [FindPendingBtcTokenSent] no token sent with block height before %d found", height)
		return make(map[uint64][]*chains.TokenSent), nil
	}

	//4. Get all token sents for the distinct block numbers
	var tokenSents []*chains.TokenSent
	result = db.RelayerClient.
		Where("source_chain = ? AND block_number IN (?)",
			sourceChain,
			distinctBlockNumbers).
		Find(&tokenSents)

	if result.Error != nil {
		return nil, fmt.Errorf("FindPendingBtcTokenSent with error: %w", result.Error)
	}

	//5. Group token sents by block number
	tokenSentsByBlock := make(map[uint64][]*chains.TokenSent)
	for _, tokenSent := range tokenSents {
		tokenSentsByBlock[tokenSent.BlockNumber] = append(tokenSentsByBlock[tokenSent.BlockNumber], tokenSent)
	}

	return tokenSentsByBlock, nil
}

/*
Remove token sents with same tx_hash due to reorg of the bitcoin
delete the token sents with the same tx_hash and block_number < the new token sent
For high performance, we insert token to a temporary table, then update of crete by join 2 tables
*/
func (db *DatabaseAdapter) SaveTokenSentsAndReorgTxes(blockNumber uint64, tokenSents []*chains.TokenSent) error {
	log.Debug().Msgf("[DatabaseAdapter] [SaveTokenSentsAndRemoveDuplicates] save token sents and remove duplicates")

	tx := db.RelayerClient.Begin()
	if tx == nil {
		return fmt.Errorf("failed to begin transaction")
	}
	defer tx.Rollback() // Will be ignored if transaction is committed
	batchSize := 100
	startRemoveIndex := 0
	// Delete reorged token sents
	for {
		hashes := make([]string, 0)
		for i := 0; i < batchSize && startRemoveIndex+i < len(tokenSents); i++ {
			hashes = append(hashes, tokenSents[startRemoveIndex+i].TxHash)
		}
		if len(hashes) == 0 {
			break
		}
		err := tx.Where("block_number < ? and tx_hash IN ?", blockNumber, hashes).Delete(&chains.TokenSent{}).Error
		if err != nil {
			return fmt.Errorf("[DatabaseAdapter] failed to remove reorged token sents: %w", err)
		}
		startRemoveIndex += len(hashes)
	}

	// Save new token sents
	//TODO: use bulk insert to improve performance
	//Limit 65535 parameter
	startSaveIndex := 0
	for {
		batch := make([]*chains.TokenSent, 0)
		for i := 0; i < batchSize && startSaveIndex+i < len(tokenSents); i++ {
			batch = append(batch, tokenSents[startSaveIndex+i])
		}
		if len(batch) == 0 {
			break
		}
		err := tx.Save(batch).Error
		if err != nil {
			return fmt.Errorf("[DatabaseAdapter] failed to save new token sents: %w", err)
		} else {
			log.Debug().Msgf("[DatabaseAdapter] [SaveTokenSentsAndReorgTxes] saved %d new token sents", len(batch))
		}
		startSaveIndex += len(batch)
	}

	// Commit the transaction
	if err := tx.Commit().Error; err != nil {
		return fmt.Errorf("[DatabaseAdapter] failed to commit transaction: %w", err)
	}

	return nil
}

func (db *DatabaseAdapter) SaveTokenSents(tokenSents []*chains.TokenSent) error {
	result := db.RelayerClient.Save(tokenSents)
	if result.Error != nil {
		return result.Error
	}
	return nil
}

// Save token sent generated by evm
func (db *DatabaseAdapter) SaveTokenSent(tokenSent chains.TokenSent, lastCheckpoint *scalarnet.EventCheckPoint) error {
	err := db.RelayerClient.Transaction(func(tx *gorm.DB) error {
		result := tx.Save(&tokenSent)
		if result.Error != nil {
			return result.Error
		}
		if lastCheckpoint != nil {
			UpdateLastEventCheckPoint(tx, lastCheckpoint)
		}
		return nil
	})
	if err != nil {
		return fmt.Errorf("failed to create evm token send: %w", err)
	}
	return nil
}

func (db *DatabaseAdapter) UpdateTokenSentsStatus(ctx context.Context, cmdIds []string, status chains.TokenSentStatus) error {
	log.Debug().Any("cmdIds", cmdIds).Msg("[DatabaseAdapter] UpdateTokenSentsStatus")
	err := db.RelayerClient.Transaction(func(tx *gorm.DB) error {
		eventIds := tx.Model(&scalarnet.TokenSentApproved{}).Select("event_id").Where("command_id IN (?)", cmdIds)
		tokenSents := []*chains.TokenSent{}
		//only update the token sent that is not success
		result := tx.Model(&chains.TokenSent{}).Where("event_id IN (?) and status != ?", eventIds, chains.TokenSentStatusSuccess).Find(&tokenSents)
		if result.Error == nil {
			ids := []string{}
			for _, tokenSent := range tokenSents {
				ids = append(ids, tokenSent.EventID)
			}
			result = tx.Model(&chains.TokenSent{}).Where("event_id IN (?)", ids).Update("status", status)
		}
		return result.Error
	})
	return err
}

func (db *DatabaseAdapter) SaveTokenDeployed(tokenDeployed *chains.TokenDeployed) error {
	result := db.RelayerClient.Save(tokenDeployed)
	if result.Error != nil {
		return result.Error
	}
	return nil
}

// CountTokenSentsByTxHashes counts the number of TokenSent records whose transaction hash appears in the input tx list
func (db *DatabaseAdapter) CountExecutedCommandByCommandIds(commandIds []string) (int64, error) {
	var count int64
	result := db.IndexerClient.Model(&chains.CommandExecuted{}).
		Where("command_id IN ?", commandIds).
		Count(&count)

	if result.Error != nil {
		return 0, fmt.Errorf("failed to count token sents by tx hashes: %w", result.Error)
	}

	return count, nil
}
